ARG BASE_IMAGE
FROM ${BASE_IMAGE}

ARG SCRIPT_DIR=/tmp/dockerfile_scripts
RUN mkdir -p ${SCRIPT_DIR}

# Remove the ompi/ucx, etc that is in the base image
# Seems that the torch installed in the NGC image links against this.
# Wonder if that will cause problems? We can have it use our OMPI but it
# also wants libucs, etc, from UCX. The NGC container must be building
# torch from source and enabling torch distributed with mpi backend.
#RUN rm -rf /opt/hpcx /usr/local/mpi

# Should we just use /container as the install dir and put
# everything (ie, ucx/ofi/ompi/mpich) under /container/{bin|lib}
# to clean up these arguments?
# Put all HPC related tools we build under /container/hpc so we can
# have a shared include, lib, bin, etc to simplify our paths and build steps.
ARG HPC_DIR=/container/hpc
RUN mkdir -p ${HPC_DIR}/bin && \
    mkdir -p ${HPC_DIR}/lib && \
    mkdir -p ${HPC_DIR}/include && \
    mkdir -p ${HPC_DIR}/share && \
    ln -s ${HPC_DIR}/lib ${HPC_DIR}/lib64
ENV LD_LIBRARY_PATH=$HPC_DIR/lib:$LD_LIBRARY_PATH
ENV PATH=$HPC_DIR/bin:$PATH

# Install Cray CXI headers/lib
COPY dockerfile_scripts/cray-libs.sh ${SCRIPT_DIR}
ARG WITH_OFI
RUN if [ "$WITH_OFI" = "1" ]; then \
    ${SCRIPT_DIR}/cray-libs.sh ; \
    fi

# Install all HPC related tools under /container (e.g., mpi, ofi, etc).
ARG WITH_MPI
ARG MPI_TYPE
ARG OMPI_WITH_CUDA=1
COPY dockerfile_scripts/ompi.sh ${SCRIPT_DIR}
RUN if [ "$WITH_MPI" = "1" ]; then \
    ${SCRIPT_DIR}/ompi.sh "$UBUNTU_VERSION" \
		 "$WITH_OFI" "$OMPI_WITH_CUDA"; \
    fi

# Enable running OMPI as root. Note that we only need this if we use OMPI. 
ENV OMPI_ALLOW_RUN_AS_ROOT ${WITH_MPI:+1}
ENV OMPI_ALLOW_RUN_AS_ROOT_CONFIRM ${WITH_MPI:+1}
# Need to override this so we don't try using the OMPI built into the
# base container, which is not built correctly for libfabric
ENV OPAL_PREFIX=${WITH_MPI:+$HPC_DIR}

ARG WITH_AWS_TRACE
COPY dockerfile_scripts/build_aws.sh ${SCRIPT_DIR}
RUN if [ "$WITH_OFI" = "1" ]; then \
    ${SCRIPT_DIR}/build_aws.sh "$WITH_OFI" "$WITH_AWS_TRACE"; \
    fi

# Try installing Horovod
ARG WITH_PT
ARG WITH_TF
COPY dockerfile_scripts/build_horovod.sh ${SCRIPT_DIR}
RUN if [ "$WITH_MPI" = "1" ] ; then \
    ${SCRIPT_DIR}/build_horovod.sh "$WITH_PT" "$WITH_TF"; \
    fi

# Set an entrypoint that can scrape up the host libfabric.so and then
# run the user command. This is intended to enable performant execution
# on non-IB systems that have a proprietary libfabric.
COPY dockerfile_scripts/scrape_libs.sh ${SCRIPT_DIR}
RUN mkdir -p /container/bin && \
    cp ${SCRIPT_DIR}/scrape_libs.sh /container/bin
ENTRYPOINT ["/container/bin/scrape_libs.sh"]

RUN rm -r /tmp/*
